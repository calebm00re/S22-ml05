{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Five: Wide and Deep Network Architectures\n",
    "## Caleb Moore, Blake Gebhardt, Christian Gould\n",
    "dataset: https://www.kaggle.com/datasets/ethanchen44/nba-playoff-predictions\n",
    "\n",
    "In this lab, we will be using machine learning to predict the winning team of NBA playoff games. We will be using the data from the 2023 NBA season. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "from numpy.linalg import pinv\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show_err=false; \n",
       "function code_toggle_err() {\n",
       " if (code_show_err){\n",
       " $('div.output_stderr').hide();\n",
       " } else {\n",
       " $('div.output_stderr').show();\n",
       " }\n",
       " code_show_err = !code_show_err\n",
       "} \n",
       "$( document ).ready(code_toggle_err);\n",
       "</script>\n",
       "To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notebook setup\n",
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show_err=false; \n",
    "function code_toggle_err() {\n",
    " if (code_show_err){\n",
    " $('div.output_stderr').hide();\n",
    " } else {\n",
    " $('div.output_stderr').show();\n",
    " }\n",
    " code_show_err = !code_show_err\n",
    "} \n",
    "$( document ).ready(code_toggle_err);\n",
    "</script>\n",
    "To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>.''')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation (4 points total)\n",
    "[1 points] Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis. Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style=\"color: green\">Load the data in!</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data in. Have to use latin-1 encoding because the data is encoded in that way.\n",
    "df = pd.read_csv('./data/nba_games.csv', encoding='latin-1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style=\"color: green\">Take a look at the data</div>\n",
    "* Here, we can see that there are some columns that we should probably not be taking into account, because they are redundant. The columns home_team and away_team give us the same data as the columns home_team_short and away_team_short. We will drop these columns.\n",
    "\n",
    "* the columns home_points and away_points actually give us the same data as the column winner, which is what we are trying to predict, so we will drop these columns as well.\n",
    "\n",
    "* the matchup_id is also irrelevant, so we will drop that as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_team</th>\n",
       "      <th>home_team_short</th>\n",
       "      <th>matchup_id</th>\n",
       "      <th>home_points</th>\n",
       "      <th>home_fg_pct</th>\n",
       "      <th>home_ft_pct</th>\n",
       "      <th>home_fg3_pct</th>\n",
       "      <th>away_team</th>\n",
       "      <th>away_team_short</th>\n",
       "      <th>away_points</th>\n",
       "      <th>away_fg_pct</th>\n",
       "      <th>away_ft_pct</th>\n",
       "      <th>away_fg3_pct</th>\n",
       "      <th>winning_team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>BOS</td>\n",
       "      <td>22201216</td>\n",
       "      <td>120</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.463</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>ATL</td>\n",
       "      <td>114</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.282</td>\n",
       "      <td>BOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Phoenix Suns</td>\n",
       "      <td>PHX</td>\n",
       "      <td>22201229</td>\n",
       "      <td>114</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.378</td>\n",
       "      <td>LA Clippers</td>\n",
       "      <td>LAC</td>\n",
       "      <td>119</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.217</td>\n",
       "      <td>LAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Denver Nuggets</td>\n",
       "      <td>DEN</td>\n",
       "      <td>22201227</td>\n",
       "      <td>109</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.250</td>\n",
       "      <td>Sacramento Kings</td>\n",
       "      <td>SAC</td>\n",
       "      <td>95</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.256</td>\n",
       "      <td>DEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Minnesota Timberwolves</td>\n",
       "      <td>MIN</td>\n",
       "      <td>22201225</td>\n",
       "      <td>113</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.361</td>\n",
       "      <td>New Orleans Pelicans</td>\n",
       "      <td>NOP</td>\n",
       "      <td>108</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.143</td>\n",
       "      <td>MIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oklahoma City Thunder</td>\n",
       "      <td>OKC</td>\n",
       "      <td>22201226</td>\n",
       "      <td>115</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.333</td>\n",
       "      <td>Memphis Grizzlies</td>\n",
       "      <td>MEM</td>\n",
       "      <td>100</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.189</td>\n",
       "      <td>OKC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                home_team home_team_short  matchup_id  home_points  \\\n",
       "0          Boston Celtics             BOS    22201216          120   \n",
       "1            Phoenix Suns             PHX    22201229          114   \n",
       "2          Denver Nuggets             DEN    22201227          109   \n",
       "3  Minnesota Timberwolves             MIN    22201225          113   \n",
       "4   Oklahoma City Thunder             OKC    22201226          115   \n",
       "\n",
       "   home_fg_pct  home_ft_pct  home_fg3_pct             away_team  \\\n",
       "0        0.472        0.786         0.463         Atlanta Hawks   \n",
       "1        0.424        0.727         0.378           LA Clippers   \n",
       "2        0.500        0.720         0.250      Sacramento Kings   \n",
       "3        0.476        0.710         0.361  New Orleans Pelicans   \n",
       "4        0.500        0.813         0.333     Memphis Grizzlies   \n",
       "\n",
       "  away_team_short  away_points  away_fg_pct  away_ft_pct  away_fg3_pct  \\\n",
       "0             ATL          114        0.454        0.789         0.282   \n",
       "1             LAC          119        0.490        0.667         0.217   \n",
       "2             SAC           95        0.435        0.667         0.256   \n",
       "3             NOP          108        0.444        0.862         0.143   \n",
       "4             MEM          100        0.435        0.722         0.189   \n",
       "\n",
       "  winning_team  \n",
       "0          BOS  \n",
       "1          LAC  \n",
       "2          DEN  \n",
       "3          MIN  \n",
       "4          OKC  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style=\"color: green\">Make the necessary changes</div>\n",
    "* Remove the columns that we do not need\n",
    "* One hot encode the data\n",
    "* Remove any n/a values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_fg_pct</th>\n",
       "      <th>home_ft_pct</th>\n",
       "      <th>home_fg3_pct</th>\n",
       "      <th>away_fg_pct</th>\n",
       "      <th>away_ft_pct</th>\n",
       "      <th>away_fg3_pct</th>\n",
       "      <th>winning_team</th>\n",
       "      <th>home_team_short_ATL</th>\n",
       "      <th>home_team_short_BKN</th>\n",
       "      <th>home_team_short_BOS</th>\n",
       "      <th>...</th>\n",
       "      <th>away_team_short_MIA</th>\n",
       "      <th>away_team_short_MIL</th>\n",
       "      <th>away_team_short_MIN</th>\n",
       "      <th>away_team_short_NOP</th>\n",
       "      <th>away_team_short_NYK</th>\n",
       "      <th>away_team_short_OKC</th>\n",
       "      <th>away_team_short_PHI</th>\n",
       "      <th>away_team_short_PHX</th>\n",
       "      <th>away_team_short_SAC</th>\n",
       "      <th>away_team_short_TOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.472</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.282</td>\n",
       "      <td>BOS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.424</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.217</td>\n",
       "      <td>LAC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.256</td>\n",
       "      <td>DEN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.476</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.143</td>\n",
       "      <td>MIN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.189</td>\n",
       "      <td>OKC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   home_fg_pct  home_ft_pct  home_fg3_pct  away_fg_pct  away_ft_pct  \\\n",
       "0        0.472        0.786         0.463        0.454        0.789   \n",
       "1        0.424        0.727         0.378        0.490        0.667   \n",
       "2        0.500        0.720         0.250        0.435        0.667   \n",
       "3        0.476        0.710         0.361        0.444        0.862   \n",
       "4        0.500        0.813         0.333        0.435        0.722   \n",
       "\n",
       "   away_fg3_pct winning_team  home_team_short_ATL  home_team_short_BKN  \\\n",
       "0         0.282          BOS                    0                    0   \n",
       "1         0.217          LAC                    0                    0   \n",
       "2         0.256          DEN                    0                    0   \n",
       "3         0.143          MIN                    0                    0   \n",
       "4         0.189          OKC                    0                    0   \n",
       "\n",
       "   home_team_short_BOS  ...  away_team_short_MIA  away_team_short_MIL  \\\n",
       "0                    1  ...                    0                    0   \n",
       "1                    0  ...                    0                    0   \n",
       "2                    0  ...                    0                    0   \n",
       "3                    0  ...                    0                    0   \n",
       "4                    0  ...                    0                    0   \n",
       "\n",
       "   away_team_short_MIN  away_team_short_NOP  away_team_short_NYK  \\\n",
       "0                    0                    0                    0   \n",
       "1                    0                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    1                    0   \n",
       "4                    0                    0                    0   \n",
       "\n",
       "   away_team_short_OKC  away_team_short_PHI  away_team_short_PHX  \\\n",
       "0                    0                    0                    0   \n",
       "1                    0                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    0                    0   \n",
       "4                    0                    0                    0   \n",
       "\n",
       "   away_team_short_SAC  away_team_short_TOR  \n",
       "0                    0                    0  \n",
       "1                    0                    0  \n",
       "2                    1                    0  \n",
       "3                    0                    0  \n",
       "4                    0                    0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the columns we don't need\n",
    "cols_we_dont_need = ['home_team', 'away_team', 'home_points', 'away_points', 'matchup_id']\n",
    "df.drop(cols_we_dont_need, axis=1, inplace=True)\n",
    "\n",
    "# One hot encode the home/away team name\n",
    "df = pd.get_dummies(df, columns=['home_team_short', 'away_team_short'])\n",
    "\n",
    "# Remove the n/a values\n",
    "df = df.dropna()\n",
    "\n",
    "# Take a look at our new dataframe\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1 points] Identify groups of features in your data that should be combined into cross-product features. Provide justification for why these features should be crossed (or why some features should not be crossed). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style=\"color: green\">Some features that should be crossed</div>\n",
    "\n",
    "1. __Home team shooting percentages vs. Away team shooting percentages:__\n",
    "\n",
    "   we will create a cross-product feature by multiplying the home team's shooting percentages with the away team's shooting percentages. This could potentially capture some interaction between the two teams' shooting performances, which is something that could come into play in a game.\n",
    "\n",
    "2. __Home team's shooting percentages vs. Away team's shooting percentages at specific distances:__\n",
    "\n",
    "   we will create cross-product features by multiplying the home team's shooting percentage from a specific distance with the away team's shooting percentage from the same distance. For example, we can multiply the home team's field goal percentage from three-point range with the away team's three-point field goal percentage. This could potentially capture some interaction between the two teams' shooting performances from specific distances"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style=\"color: green\">A feature that should not be crossed</div>\n",
    "1. __Home team's shooting percentages vs. Home team's free throw percentages:__\n",
    "\n",
    "  We will not create a cross-product feature with these two features, because it would simply not add much to the model. The home team's shooting percentages and the home team's free throw percentages are two very related features, so it would not make sense to multiply them together.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style=\"color: green\">Crossing the features we want!</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['home_shooting_away_shooting_cross'] = df.apply(lambda row: row['home_fg_pct'] * row['away_fg_pct'], axis=1)\n",
    "df['home_shooting_away_shooting_3pt_cross'] = df.apply(lambda row: row['home_fg3_pct'] * row['away_fg3_pct'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1 points] Choose and explain what metric(s) you will use to evaluate your algorithm’s performance. You should give a detailed argument for why this (these) metric(s) are appropriate on your data. That is, why is the metric appropriate for the task (e.g., in terms of the business case for the task). Please note: rarely is accuracy the best evaluation metric to use. Think deeply about an appropriate measure of performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing a metric\n",
    "\n",
    "#### <div style=\"color: green\">What is our purpose?</div>\n",
    "* Before we can choose a proper metric, we need to know and define exactly what our purpose in this report is. Our purpose is to be able to take in data for two teams, and be able to predict which team will win the game.\n",
    "\n",
    "#### <div style=\"color: green\">Then what metric should we use?</div>\n",
    "* Even though in most cases with machine learning, accuracy is not the best metric to use, in this case, it is the best metric to use, because we would want to be able to predict the winner of the game as accurately as possible. Because of the nature of this problem, there really isn't another metric that we can really use. \n",
    "\n",
    "* Something like precision, which would be helpful in a lot of cases, would not really be useful to us, because every game is a binary outcome, and the stats of a team is always changing. We want to be able to have a model that can predict the winner of a game, not a model that consistently picks a winner given certain conditions, regardless of who would win.\n",
    "\n",
    "#### <div style=\"color: green\">Our metric</div>\n",
    "* So, then since we are going to be using accuracy, we will shoot for an accuracy of over 54%, since the accuracy of most sports betting systems achieve an accuracy of 54%, according to [this article](https://graham-kendall.com/blog/sports-forecasting-a-comparison-of-the-forecast-accuracy-of-prediction-markets-betting-odds-and-tipsters/)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1 points] Choose the method you will use for dividing your data into training and testing (i.e., are you using Stratified 10-fold cross validation? Shuffle splits? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. Argue why your cross validation method is a realistic mirroring of how an algorithm would be used in practice. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Choosing a method for splitting the data\n",
    "\n",
    "\n",
    "#### <span style=\"color: green\">What is our purpose?</span>\n",
    "* Again, before we look into splitting our data, we need to take a close look at our purpose. Since our purpose is a binary classifier, we need to make sure that both of our classes are represented equally in our training and testing data. Home teams and Away teams are in the dataset. We need to make sure that both of these classes are represented equally in our training and testing data.\n",
    "\n",
    "#### <div style=\"color: green\">Which classifier fulfills our purpose best?</div>\n",
    "* 10-fold cross-validation is generally recommended for small to medium-sized datasets, where the goal is to maximize the use of the available data and obtain a more stable estimate of the model's performance. However, if we were using a larger dataset, it would probably be easier to use a simpler method, such as a single random split of the data into training and testing sets.\n",
    "\n",
    "* Our dataset is not too large, so we will be using 10-fold cross-validation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style=\"color: green\">Setup the 10 fold cross validation</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(X, y, model):\n",
    "  \"\"\"\n",
    "  Runs 10-fold cross-validation on the input data and model.\n",
    "\n",
    "  Args:\n",
    "  - X: A pandas DataFrame of features.\n",
    "  - y: A pandas Series of target labels.\n",
    "  - model: A scikit-learn model object.\n",
    "\n",
    "  Returns:\n",
    "  - number: The average accuracy score across all folds.\n",
    "  \"\"\"\n",
    "  # Initialize the KFold object with 10 folds\n",
    "  kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "  # Initialize a list to store the accuracy scores for each fold\n",
    "  scores = []\n",
    "\n",
    "  # Loop through each fold and train/test the model\n",
    "  for train_index, test_index in kf.split(X):\n",
    "      X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "      y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "      model.fit(X_train, y_train)\n",
    "      score = model.score(X_test, y_test)\n",
    "      scores.append(score)\n",
    "\n",
    "  return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        1\n",
      "2        2\n",
      "3        3\n",
      "4        4\n",
      "        ..\n",
      "3270     5\n",
      "3271    13\n",
      "3272     7\n",
      "3273     1\n",
      "3274     6\n",
      "Name: winning_team, Length: 3271, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separate our X and y\n",
    "X = df.drop('winning_team', axis=1)\n",
    "y = df['winning_team']\n",
    "\n",
    "# assign a number to each team name in the winning_team column\n",
    "team_names = y.unique()\n",
    "team_names_dict = {team_names[i]: i for i in range(len(team_names))}\n",
    "y = y.map(team_names_dict)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy score for basic linear regression: 0.5628300514656522\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "# Print the average accuracy score over all folds for a basic linear regression model\n",
    "print(\"Average accuracy score for basic linear regression:\", get_acc(X, y, model))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sweet! We have a basic model with linear regression that already is performing pretty well. Let's see if we can improve it by using different models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling (5 points total)\n",
    "[2 points] Create at least three combined wide and deep networks to classify your data using Keras. Visualize the performance of the network on the training data and validation data in the same plot versus the training iterations. Note: use the \"history\" return parameter that is part of Keras \"fit\" function to easily access this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wide_and_deep_network(wide_layer_size, deep_layer_sizes):\n",
    "    # Wide part of the network\n",
    "    wide_input = Input(shape=(wide_layer_size,))\n",
    "    \n",
    "    # Deep part of the network\n",
    "    deep_input = Input(shape=(deep_layer_sizes[0],))\n",
    "    deep = deep_input\n",
    "    for layer_size in deep_layer_sizes[1:]:\n",
    "        deep = Dense(layer_size, activation='relu')(deep)\n",
    "\n",
    "    # Combine wide and deep parts\n",
    "    combined = Concatenate()([wide_input, deep])\n",
    "\n",
    "    # Output layer\n",
    "    output = Dense(1, activation='sigmoid')(combined)\n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=[wide_input, deep_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup X_wide and X_deep\n",
    "stopping_point = 8\n",
    "\n",
    "# Wide part - cross-product of one-hot encoded team names\n",
    "X_wide = X.iloc[:, :stopping_point]\n",
    "\n",
    "# Deep part - embedding of one-hot encoded team names combined with numerical features\n",
    "X_deep = pd.concat([X.iloc[:, :stopping_point], X.iloc[:, stopping_point:]], axis=1)\n",
    "\n",
    "X_wide = X_wide.values\n",
    "X_deep = X_deep.values\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Validation Accuracy: 0.0518\n",
      "Fold 2 Validation Accuracy: 0.0489\n",
      "Fold 3 Validation Accuracy: 0.0489\n",
      "Fold 4 Validation Accuracy: 0.0489\n",
      "Fold 5 Validation Accuracy: 0.0489\n",
      "Fold 6 Validation Accuracy: 0.0520\n",
      "Fold 7 Validation Accuracy: 0.0520\n",
      "Fold 8 Validation Accuracy: 0.0520\n",
      "Fold 9 Validation Accuracy: 0.0520\n",
      "Fold 10 Validation Accuracy: 0.0520\n",
      "Average Validation Accuracy: 0.0507\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "fold = 1\n",
    "avg_val_accuracy = []\n",
    "\n",
    "for train_index, val_index in skf.split(X_wide, y):\n",
    "    X_wide_train, X_wide_val = X_wide[train_index], X_wide[val_index]\n",
    "    X_deep_train, X_deep_val = X_deep[train_index], X_deep[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "    model = create_wide_and_deep_network(stopping_point, [48, 8, 16])  # Adjust the parameters based on your specific dataset\n",
    "    history = model.fit([X_wide_train, X_deep_train], y_train, validation_data=([X_wide_val, X_deep_val], y_val), epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "    val_accuracy = history.history['val_accuracy'][-1]\n",
    "    avg_val_accuracy.append(val_accuracy)\n",
    "\n",
    "    print(f\"Fold {fold} Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    fold += 1\n",
    "\n",
    "print(f\"Average Validation Accuracy: {np.mean(avg_val_accuracy):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, title):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2 points] Investigate generalization performance by altering the number of layers in the deep branch of the network. Try at least two different number of layers. Use the method of cross validation and evaluation metric that you argued for at the beginning of the lab to select the number of layers that performs superiorly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1 points] Compare the performance of your best wide and deep network to a standard multi-layer perceptron (MLP). Alternatively, you can compare to a network without the wide branch (i.e., just the deep network). .  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exceptional Work (1 points total)\n",
    "(0.4) The overall quality of the report as a coherent, useful, complete and polished product will be reflected here. Did you support your reasons for creating cross categories? Did you include plots and provide interpretation? Did you justify your choice of metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(0.6) Additional analysis\n",
    "(5000 level) You have free rein to provide any additional analyses and visualizations appropriate to your data.  Implement additional optimization models or statistical analysis.\n",
    " ( 7000 level students - options):\n",
    "Capture the embedding weights from the deep network and (if needed) perform dimensionality reduction on the output of these embedding layers (only if needed). That is, pass the observations into the network, save the embedded weights (called embeddings), and then perform  dimensionality reduction in order to visualize results. Visualize and explain any clusters in the data.\n",
    "Use statistical methods to compare the performance of different models.  For classification tasks, you ight compare using the receiver operating characteristic and area under the curve. For regression tasks, you might use use Bland-Altman plots and residual variance calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4045ce629ca2404df8e09a4bb72649c60795682d1cc7b69b21add64452ef6fa4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
